diff --git a/Makefile b/Makefile
index 39a99d7..c387332 100644
--- a/Makefile
+++ b/Makefile
@@ -132,6 +132,8 @@ UPROGS=\
 	$U/_grind\
 	$U/_wc\
 	$U/_zombie\
+	$U/_thread\
+	$U/_producer_consumer\
 
 fs.img: mkfs/mkfs README $(UPROGS)
 	mkfs/mkfs fs.img README $(UPROGS)
diff --git a/kernel/defs.h b/kernel/defs.h
index a3c962b..5cd9971 100644
--- a/kernel/defs.h
+++ b/kernel/defs.h
@@ -106,7 +106,11 @@ void            yield(void);
 int             either_copyout(int user_dst, uint64 dst, void *src, uint64 len);
 int             either_copyin(void *dst, int user_src, uint64 src, uint64 len);
 void            procdump(void);
-
+int             createThread(uint64, uint64, uint64); // OFFLINE-5.................
+void            exitThread(int); 
+int             joinThread(uint64,int);
+int             atomic_sleep(uint64);
+int             thread_wakeup(int);
 // swtch.S
 void            swtch(struct context*, struct context*);
 
@@ -173,6 +177,9 @@ uint64          walkaddr(pagetable_t, uint64);
 int             copyout(pagetable_t, uint64, char *, uint64);
 int             copyin(pagetable_t, char *, uint64, uint64);
 int             copyinstr(pagetable_t, char *, uint64, uint64);
+int             uvmSameMem(pagetable_t, pagetable_t, uint64); // for OFFLINE-5....
+int             uvmSameMemRange(pagetable_t, pagetable_t, uint64, uint64);
+int             release_lock(pagetable_t, uint64);
 
 // plic.c
 void            plicinit(void);
diff --git a/kernel/proc.c b/kernel/proc.c
index 959b778..615203d 100644
--- a/kernel/proc.c
+++ b/kernel/proc.c
@@ -13,6 +13,14 @@ struct proc proc[NPROC];
 struct proc *initproc;
 
 int nextpid = 1;
+
+
+//******************OFFLINE-5 maintain pg_id for shared page table.....
+int nextpgId=1;
+struct spinlock pgId_lock;
+
+
+
 struct spinlock pid_lock;
 
 extern void forkret(void);
@@ -102,6 +110,23 @@ allocpid()
   return pid;
 }
 
+
+//**********OFFLINE-5......allocated memId...
+int
+allocPgId()
+{
+  int pg_id;
+  
+  acquire(&pgId_lock);
+  pg_id = nextpgId;
+  nextpgId = nextpgId + 1;
+  release(&pgId_lock);
+
+  return pg_id;
+}
+
+
+
 // Look in the process table for an UNUSED proc.
 // If found, initialize state required to run in the kernel,
 // and return with p->lock held.
@@ -123,6 +148,7 @@ allocproc(void)
 
 found:
   p->pid = allocpid();
+  p->pg_id=allocPgId(); // **********OFFLINE-5 ...for page table sharing...
   p->state = USED;
 
   // Allocate a trapframe page.
@@ -159,7 +185,22 @@ freeproc(struct proc *p)
     kfree((void*)p->trapframe);
   p->trapframe = 0;
   if(p->pagetable)
-    proc_freepagetable(p->pagetable, p->sz);
+  {
+    //***********OFFLINE-5.... for threads, we will simply unmap the pagetable, we can't free the pagetable............
+    if(p->is_thread==0)
+    {
+      proc_freepagetable(p->pagetable, p->sz);
+    }
+    else
+    {
+      uvmunmap(p->pagetable, TRAMPOLINE, 1, 0);  
+      uvmunmap(p->pagetable, TRAPFRAME, 1, 0);
+      uvmunmap(p->pagetable, 0, PGROUNDUP(p->sz)/PGSIZE, 0); // last parameter 0 means only unmap
+
+    }
+
+  }
+    
   p->pagetable = 0;
   p->sz = 0;
   p->pid = 0;
@@ -261,6 +302,13 @@ growproc(int n)
 {
   uint64 sz;
   struct proc *p = myproc();
+  
+  //*************** OFFLINE-5...acquire lock for all threads with same page id so that they can't grow simulteneously
+  struct proc *pp;
+  for(pp = proc; pp < &proc[NPROC]; pp++){
+    if(pp->pg_id==p->pg_id)
+      acquire(&pp->pgLock);
+  }
 
   sz = p->sz;
   if(n > 0){
@@ -271,6 +319,36 @@ growproc(int n)
     sz = uvmdealloc(p->pagetable, sz, sz + n);
   }
   p->sz = sz;
+
+
+  //************ OFFLINE-5.....now we allocated the page table. 
+  // now we need to map or unmap the new allocated or deallocated pages to all the threads//
+
+  for(pp = proc; pp < &proc[NPROC]; pp++){
+    if(pp->pg_id==p->pg_id && pp->pid!=p->pid)
+    {
+      if(n > 0){
+        if(uvmSameMemRange(p->pagetable, pp->pagetable, pp->sz,p->sz)<0) {
+        return -1;
+        }
+      } else if(n < 0){
+        // unmap but no need to delete..........................
+        uvmunmap(pp->pagetable, PGROUNDUP(p->sz), (PGROUNDUP(pp->sz)-PGROUNDUP(p->sz))/ PGSIZE, 0);
+      }
+
+      pp->sz=p->sz;
+
+    }
+
+  }
+
+  //lastly, release the locks...............
+  for(pp = proc; pp < &proc[NPROC]; pp++){
+    if(pp->pg_id==p->pg_id)
+      release(&pp->pgLock);
+  }
+
+
   return 0;
 }
 
@@ -325,6 +403,80 @@ fork(void)
   return pid;
 }
 
+
+
+int
+createThread(uint64 functionPointer, uint64 argumentPointer, uint64 stackPointer)
+{
+  int i, pid;
+  struct proc *np;
+  struct proc *p = myproc();
+
+  // Allocate process.
+  if((np = allocproc()) == 0){
+    return -1;
+  }
+
+  // *************OFFLINE-5 Copy user memory from parent to child.
+  if(uvmSameMem(p->pagetable, np->pagetable, p->sz) < 0){
+    freeproc(np);
+    release(&np->lock);
+    return -1;
+  }
+  np->sz = p->sz;
+
+  // copy saved user registers.
+  *(np->trapframe) = *(p->trapframe);
+
+
+
+
+  // *******OFFLINE-5 update the trapframe...........
+  // function arguments...............
+  np->trapframe->a0 = argumentPointer;
+  // starting function.................
+  np->trapframe->epc=functionPointer;
+  // stack address....(+4096 because sp is decremented before push)
+  np->trapframe->sp=stackPointer+4096;
+  np->trapframe->sp -= np->trapframe->sp % 16;
+
+  printf(" argument pointer: %x\n",functionPointer);
+
+  // make is_thread true..........
+  np->is_thread=1;
+  // they have the same page table
+  np->pg_id=p->pg_id;
+
+
+
+
+
+
+  // increment reference counts on open file descriptors.
+  for(i = 0; i < NOFILE; i++)
+    if(p->ofile[i])
+      np->ofile[i] = filedup(p->ofile[i]);
+  np->cwd = idup(p->cwd);
+
+  safestrcpy(np->name, p->name, sizeof(p->name));
+
+  pid = np->pid;
+
+  release(&np->lock);
+
+  acquire(&wait_lock);
+  np->parent = p;
+  release(&wait_lock);
+
+  acquire(&np->lock);
+  np->state = RUNNABLE;
+  release(&np->lock);
+
+  return pid;
+}
+
+
+
 // Pass p's abandoned children to init.
 // Caller must hold wait_lock.
 void
@@ -385,6 +537,50 @@ exit(int status)
   panic("zombie exit");
 }
 
+
+void
+exitThread(int status)
+{
+  struct proc *p = myproc();
+
+  if(p == initproc)
+    panic("init exiting");
+
+  // Close all open files.
+  for(int fd = 0; fd < NOFILE; fd++){
+    if(p->ofile[fd]){
+      struct file *f = p->ofile[fd];
+      fileclose(f);
+      p->ofile[fd] = 0;
+    }
+  }
+
+  begin_op();
+  iput(p->cwd);
+  end_op();
+  p->cwd = 0;
+
+  acquire(&wait_lock);
+
+  // Give any children to init.
+  reparent(p);
+
+  // Parent might be sleeping in wait().
+  wakeup(p->parent);
+  
+  acquire(&p->lock);
+
+  p->xstate = status;
+  p->state = ZOMBIE;
+
+  release(&wait_lock);
+
+  // Jump into the scheduler, never to return.
+  sched();
+  panic("zombie exit");
+}
+
+
 // Wait for a child process to exit and return its pid.
 // Return -1 if this process has no children.
 int
@@ -434,6 +630,55 @@ wait(uint64 addr)
   }
 }
 
+int
+joinThread(uint64 addr,int threadId)
+{
+  struct proc *pp;
+  int havekids, pid;
+  struct proc *p = myproc();
+
+  acquire(&wait_lock);
+
+  for(;;){
+    // Scan through table looking for exited children.
+    havekids = 0;
+    for(pp = proc; pp < &proc[NPROC]; pp++){
+      if(pp->pid==threadId){ // OFFLINE-5...check if it is the thread for what I want to wait
+        // make sure the child isn't still in exit() or swtch().
+        acquire(&pp->lock);
+
+        havekids = 1;
+        if(pp->state == ZOMBIE){
+          // Found one.
+          pid = pp->pid;
+          if(addr != 0 && copyout(p->pagetable, addr, (char *)&pp->xstate,
+                                  sizeof(pp->xstate)) < 0) {
+            release(&pp->lock);
+            release(&wait_lock);
+            return -1;
+          }
+          freeproc(pp);
+          release(&pp->lock);
+          release(&wait_lock);
+          return pid;
+        }
+        release(&pp->lock);
+      }
+    }
+
+    // No point waiting if we don't have any children.
+    if(!havekids || killed(p)){
+      release(&wait_lock);
+      return -1;
+    }
+    
+    // Wait for a child to exit.
+    sleep(p, &wait_lock);  //DOC: wait-sleep
+  }
+}
+
+
+
 // Per-CPU process scheduler.
 // Each CPU calls scheduler() after setting itself up.
 // Scheduler never returns.  It loops, doing:
@@ -561,6 +806,32 @@ sleep(void *chan, struct spinlock *lk)
   acquire(lk);
 }
 
+
+//OFFLINE-5.........................
+int
+atomic_sleep(uint64 lockaddr)
+{
+  struct proc *p = myproc();
+  
+  // Must acquire p->lock in order to
+  // change p->state and then call sched.
+  // Once we hold p->lock, we can be
+  // guaranteed that we won't miss any wakeup
+  // (wakeup locks p->lock),
+  // so it's okay to release lk.
+
+  acquire(&p->lock);  //DOC: sleeplock1
+  int q=release_lock(p->pagetable,lockaddr);
+  // Go to sleep.
+  p->state = SLEEPING;
+
+  sched();
+  // Reacquire original lock.
+  release(&p->lock);
+  return q;
+}
+
+
 // Wake up all processes sleeping on chan.
 // Must be called without any p->lock.
 void
@@ -579,6 +850,28 @@ wakeup(void *chan)
   }
 }
 
+//OFFLINE-5................................
+int
+thread_wakeup(int pid)
+{
+  struct proc *p;
+  int q=-1;
+
+
+  for(p = proc; p < &proc[NPROC]; p++) {
+    if(p != myproc()){
+      acquire(&p->lock);
+      if(p->state == SLEEPING && p->pid == pid) { // pid instead of chan....................
+        p->state = RUNNABLE;
+        q=0;
+      }
+      release(&p->lock);
+    }
+  }
+  return q;
+}
+
+
 // Kill the process with the given pid.
 // The victim won't exit until it tries to return
 // to user space (see usertrap() in trap.c).
diff --git a/kernel/proc.h b/kernel/proc.h
index d021857..7a9eee1 100644
--- a/kernel/proc.h
+++ b/kernel/proc.h
@@ -104,4 +104,10 @@ struct proc {
   struct file *ofile[NOFILE];  // Open files
   struct inode *cwd;           // Current directory
   char name[16];               // Process name (debugging)
+
+  int is_thread;               // for OFFLINE-5...............
+  int pg_id;
+  struct spinlock pgLock;
+  
+  
 };
diff --git a/kernel/syscall.c b/kernel/syscall.c
index ed65409..4d5aa28 100644
--- a/kernel/syscall.c
+++ b/kernel/syscall.c
@@ -101,6 +101,12 @@ extern uint64 sys_unlink(void);
 extern uint64 sys_link(void);
 extern uint64 sys_mkdir(void);
 extern uint64 sys_close(void);
+extern uint64 sys_thread_create(void); //OFFLINE-5............
+extern uint64 sys_thread_join(void);
+extern uint64 sys_thread_exit(void);
+extern uint64 sys_atomic_sleep(void);
+extern uint64 sys_thread_wakeup(void);
+
 
 // An array mapping syscall numbers from syscall.h
 // to the function that handles the system call.
@@ -126,6 +132,11 @@ static uint64 (*syscalls[])(void) = {
 [SYS_link]    sys_link,
 [SYS_mkdir]   sys_mkdir,
 [SYS_close]   sys_close,
+[SYS_thread_create]   sys_thread_create,
+[SYS_thread_join]   sys_thread_join,
+[SYS_thread_exit]   sys_thread_exit,
+[SYS_atomic_sleep]   sys_atomic_sleep,
+[SYS_thread_wakeup]   sys_thread_wakeup,
 };
 
 void
diff --git a/kernel/syscall.h b/kernel/syscall.h
index bc5f356..db51885 100644
--- a/kernel/syscall.h
+++ b/kernel/syscall.h
@@ -20,3 +20,8 @@
 #define SYS_link   19
 #define SYS_mkdir  20
 #define SYS_close  21
+#define SYS_thread_create 22
+#define SYS_thread_join 23
+#define SYS_thread_exit 24
+#define SYS_atomic_sleep 25
+#define SYS_thread_wakeup 26
\ No newline at end of file
diff --git a/kernel/sysproc.c b/kernel/sysproc.c
index 1de184e..703b585 100644
--- a/kernel/sysproc.c
+++ b/kernel/sysproc.c
@@ -89,3 +89,49 @@ sys_uptime(void)
   release(&tickslock);
   return xticks;
 }
+
+
+// for OFFLINE-5.................
+
+uint64
+sys_thread_create(void)
+{
+  uint64 p,q,r;
+  argaddr(0, &p);
+  argaddr(1, &q);
+  argaddr(2, &r);
+  return createThread(p,q,r);
+}
+
+uint64
+sys_thread_join(void)
+{
+  int p;
+  argint(0, &p);
+  return joinThread(0,p);
+}
+
+uint64
+sys_thread_exit(void)
+{
+  exitThread(1);
+  return 0;
+ 
+}
+
+uint64
+sys_atomic_sleep(void)
+{
+  uint64 lockaddr;
+  argaddr(0,&lockaddr);
+  return atomic_sleep(lockaddr);
+  
+}
+
+uint64
+sys_thread_wakeup(void){
+  int pid;
+  argint(0,&pid);
+  return thread_wakeup(pid);
+
+}
diff --git a/kernel/vm.c b/kernel/vm.c
index 9f69783..a814a54 100644
--- a/kernel/vm.c
+++ b/kernel/vm.c
@@ -332,6 +332,83 @@ uvmcopy(pagetable_t old, pagetable_t new, uint64 sz)
   return -1;
 }
 
+
+//********** OFFLINE-5 .....the new page table should have the same memory.............
+
+//map the pages from 0 to sz.........................
+int
+uvmSameMem(pagetable_t old, pagetable_t new, uint64 sz)
+{
+  pte_t *pte;
+  uint64 pa, i;
+  uint flags;
+
+  //char *mem;
+
+  for(i = 0; i < sz; i += PGSIZE){
+    if((pte = walk(old, i, 0)) == 0)
+      panic("uvmcopy: pte should exist");
+    if((*pte & PTE_V) == 0)
+      panic("uvmcopy: page not present");
+    pa = PTE2PA(*pte);
+    flags = PTE_FLAGS(*pte);
+
+    // don't allocate a new memory!!!...............
+    // if((mem = kalloc()) == 0)
+    //   goto err;
+    //memmove(mem, (char*)pa, PGSIZE);
+
+    // map at the same address
+    if(mappages(new, i, PGSIZE, pa, flags) != 0){
+      //kfree(mem);
+      goto err;
+    }
+  }
+  return 0;
+
+ err:
+  uvmunmap(new, 0, i / PGSIZE, 1);
+  return -1;
+}
+
+//map the pages from old size to new size (after growproc)
+int
+uvmSameMemRange(pagetable_t old, pagetable_t new, uint64 old_sz,uint64 new_sz)
+{
+  pte_t *pte;
+  uint64 pa, i;
+  uint flags;
+
+  //char *mem;
+
+  for(i = old_sz; i < new_sz; i += PGSIZE){
+    if((pte = walk(old, i, 0)) == 0)
+      panic("uvmcopy: pte should exist");
+    if((*pte & PTE_V) == 0)
+      panic("uvmcopy: page not present");
+    pa = PTE2PA(*pte);
+    flags = PTE_FLAGS(*pte);
+
+    // don't allocate a new memory!!!...............
+    // if((mem = kalloc()) == 0)
+    //   goto err;
+    //memmove(mem, (char*)pa, PGSIZE);
+
+    // map at the same address
+    if(mappages(new, i, PGSIZE, pa, flags) != 0){
+      //kfree(mem);
+      goto err;
+    }
+  }
+  return 0;
+
+ err:
+  uvmunmap(new, 0, i / PGSIZE, 1);
+  return -1;
+}
+
+
+
 // mark a PTE invalid for user access.
 // used by exec for the user stack guard page.
 void
@@ -395,6 +472,29 @@ copyin(pagetable_t pagetable, char *dst, uint64 srcva, uint64 len)
   return 0;
 }
 
+
+
+int
+release_lock(pagetable_t pagetable, uint64 destinationVirtualAddr)
+{
+
+  // release going to the physical address... and we can get the mapping in page table......
+  uint64  startVirtualAddr, startPhyAddr;
+
+  startVirtualAddr = PGROUNDDOWN(destinationVirtualAddr);
+  startPhyAddr = walkaddr(pagetable, startVirtualAddr);
+  if(startPhyAddr == 0)
+    return -1;
+
+  __sync_synchronize();
+  __sync_lock_release((uint8*)(startPhyAddr + (destinationVirtualAddr - startVirtualAddr)));
+ 
+  return 0;
+}
+
+
+
+
 // Copy a null-terminated string from user to kernel.
 // Copy bytes to dst from virtual address srcva in a given page table,
 // until a '\0', or max.
diff --git a/user/producer_consumer.c b/user/producer_consumer.c
new file mode 100644
index 0000000..47cca60
--- /dev/null
+++ b/user/producer_consumer.c
@@ -0,0 +1,101 @@
+#include "kernel/types.h"
+#include "kernel/stat.h"
+#include "user/user.h"
+#include "user/user_semaphore.h"
+
+struct thread_mutex printLock;
+
+
+struct queue q;
+struct thread_mutex mux;// a mutex object lock 
+struct sem_t empty;// a semaphore object empty
+struct sem_t full;// a semaphore object full
+
+
+void init_semaphore()
+{
+	thread_mutex_init(&mux);// initialize mutex lock
+	sem_init(&empty,5);// initialize semaphore empty with 5
+	sem_init(&full,0);// initialize semaphore full with 0
+
+}
+
+void  ProducerFunc(void * arg)
+{	
+	thread_mutex_lock(&printLock);
+	printf("%s\n",(char*)arg);
+	thread_mutex_unlock(&printLock);
+	int i;
+	for(i=1;i<=10;i++)
+	{
+		
+		sem_wait(&empty);// wait for semphore empty
+		
+		thread_mutex_lock(&mux);// wait for mutex lock
+		sleep(1);	
+		push(&q,i);
+		thread_mutex_lock(&printLock);
+		printf("producer produced item %d\n",i);
+		thread_mutex_unlock(&printLock);
+		
+		thread_mutex_unlock(&mux);	// unlock mutex lock
+		
+		sem_post(&full);// post semaphore full
+	}
+	
+	thread_exit() ; // extra added....................
+}
+
+void  ConsumerFunc(void * arg)
+{
+	thread_mutex_lock(&printLock);
+	printf("%s\n",(char*)arg);
+	thread_mutex_unlock(&printLock);
+	
+	int i;
+	for(i=1;i<=10;i++)
+	{	
+		
+		sem_wait(&full); // wait for semphore full
+		
+ 		thread_mutex_lock(&mux);// wait for mutex lock
+			
+		sleep(1);
+		int item = front(&q);
+		pop(&q);
+		thread_mutex_lock(&printLock);
+		printf("consumer consumed item %d\n",item);	
+		thread_mutex_unlock(&printLock);
+
+		
+		thread_mutex_unlock(&mux); // unlock mutex lock
+		
+		sem_post(&empty);	// post semaphore empty	
+	}
+	
+	thread_exit();
+}
+
+int main(void)
+{	
+	
+	init_semaphore();
+	thread_mutex_init(&printLock);
+	char * message1 = "i am producer";
+	char * message2 = "i am consumer";
+
+
+	void *s1, *s2;
+  	int thread1, thread2;
+
+  	s1 = malloc(4096);
+  	s2 = malloc(4096);
+
+  	thread1 = thread_create(ProducerFunc, (void*)message1, s1);
+  	thread2 = thread_create(ConsumerFunc, (void*)message2, s2); 
+
+  	thread_join(thread1);
+  	thread_join(thread2);	
+	
+	exit(0);
+}
diff --git a/user/thread.c b/user/thread.c
new file mode 100644
index 0000000..36487c4
--- /dev/null
+++ b/user/thread.c
@@ -0,0 +1,87 @@
+#include "kernel/types.h"
+#include "kernel/stat.h"
+#include "user/user.h"
+#include "user/user_mutexlock.h"
+#include "user/user_spinLock.h"
+
+struct thread_mutex printLock;
+
+struct balance {
+    char name[32];
+    int amount;
+};
+
+struct thread_spinlock lock;
+struct thread_mutex mlock;
+
+
+volatile int total_balance = 0;
+//volatile int missed_balance = 0;
+volatile unsigned int delay (unsigned int d) {
+   unsigned int i; 
+   for (i = 0; i < d; i++) {
+       __asm volatile( "nop" ::: );
+   }
+
+   return i;   
+}
+
+void do_work(void *arg){
+    int i; 
+    int old;
+   
+    struct balance *b = (struct balance*) arg; 
+    thread_mutex_lock(&printLock);
+    printf( "Starting do_work: s:%s\n", b->name);
+    thread_mutex_unlock(&printLock);
+
+    
+
+    for (i = 0; i < b->amount; i++) { 
+        // lock and mlock will be implemented by you.
+        thread_spin_lock(&lock);
+        //thread_mutex_lock(&mlock);
+         old = total_balance;
+         delay(100000);
+         //missed_balance=total_balance-old;
+	    //if(old != total_balance)  printf("we will miss an update. old: %d total_balance: %d\n", old, total_balance);
+         total_balance = old + 1;
+         //total_balance++;
+         
+         thread_spin_unlock(&lock);
+         //thread_mutex_unlock(&mlock);
+
+    }
+  
+    printf( "Done s:%x\n", b->name);
+
+    thread_exit();
+    return;
+}
+
+int main(int argc, char *argv[]) {
+  thread_spin_init(&lock);
+  thread_mutex_init(&mlock);
+  thread_mutex_init(&printLock);
+
+  struct balance b1 = {"b1", 3000};
+  struct balance b2 = {"b2", 2000};
+ 
+  void *s1, *s2;
+  int thread1, thread2, r1, r2;
+
+  s1 = malloc(4096); // 4096 is the PGSIZE defined in kernel/riscv.h
+  //sleep(50);
+  s2 = malloc(4096);
+
+  thread1 = thread_create(do_work, (void*)&b1, s1);
+  thread2 = thread_create(do_work, (void*)&b2, s2); 
+
+  r1 = thread_join(thread1);
+  r2 = thread_join(thread2);
+  
+  printf("Threads finished: (%d):%d, (%d):%d, shared balance:%d \n", 
+      thread1, r1, thread2, r2, total_balance);
+
+  exit(1);
+}
\ No newline at end of file
diff --git a/user/thread_queue.h b/user/thread_queue.h
new file mode 100644
index 0000000..fbaf910
--- /dev/null
+++ b/user/thread_queue.h
@@ -0,0 +1,39 @@
+#include "kernel/types.h"
+#include "user/user.h"
+
+
+///needed for conditional.................
+
+struct queue
+{
+    int arr[16];
+    int front;
+    int rear;
+    int size;
+};
+
+void queue_init(struct queue *q)
+{
+    q->front = 0;
+    q->rear = 0;
+    q->size = 0;
+}
+void push(struct queue *q, int x)
+{
+    q->arr[q->rear] = x;
+    q->rear = (q->rear + 1) % 16;
+    q->size++;
+}
+int front(struct queue *q)
+{
+    if (q->size == 0)
+        return -1;
+    return q->arr[q->front];
+}
+void pop(struct queue *q)
+{
+    if (q->size == 0)
+        return;
+    q->front = (q->front + 1) % 16;
+    q->size--;
+}
diff --git a/user/user.h b/user/user.h
index 4d398d5..b39ae57 100644
--- a/user/user.h
+++ b/user/user.h
@@ -22,6 +22,11 @@ int getpid(void);
 char* sbrk(int);
 int sleep(int);
 int uptime(void);
+int thread_create(void(*fcn)(void*), void *arg, void*stack);//OFFLINE-5...........
+int thread_join(int thread_id);
+int thread_exit(void);
+int atomic_sleep(uint8*);
+int thread_wakeup(int);
 
 // ulib.c
 int stat(const char*, struct stat*);
diff --git a/user/user_conditional.h b/user/user_conditional.h
new file mode 100644
index 0000000..58b564f
--- /dev/null
+++ b/user/user_conditional.h
@@ -0,0 +1,60 @@
+#include "kernel/types.h"
+#include "kernel/param.h"
+#include "user/user.h"
+#include "user_mutexlock.h"
+#include "thread_queue.h"
+
+// I followed this resource...................
+//https://www.andrew.cmu.edu/course/15-440-sp11/applications/ln/lecture7.html
+
+
+struct conditional_variable
+{
+    struct queue q;
+    struct thread_mutex mux; /*protects queue */
+};
+
+void thread_cond_init(struct conditional_variable *conv)
+{
+    queue_init(&(conv->q));
+    thread_mutex_init(&(conv->mux));
+}
+
+
+
+// 1) here, the mutex passed as parameter is already locked.....
+// 2) we need to release the lock before going to sleeep...........
+// 3) after the wakeup, the locked is acquired again
+
+//****************CHALLENGE!!!!!...... we need to release the lock before going to sleep.. but in between them,
+// wakeup can be called !!!!!!!!!!!!!!!!!! *****************************************
+
+void thread_cond_wait(struct conditional_variable *conv, struct thread_mutex *mutex)
+{
+    thread_mutex_lock(&conv->mux);   /* protect the queue */
+    push(&(conv->q), getpid());     /* enqueue */
+    thread_mutex_unlock(&conv->mux); /* we're done with the list */
+
+    /* The suspend and release_mutex() operation should be atomic  */
+    // and this work is done by a system call where the kernel releases the lock accessing the physical address 
+
+    atomic_sleep(&(mutex->locked)); /* Sleep 'til someone wakes us */
+    thread_mutex_lock(mutex); /* Woke up -- our turn, get resource lock */
+
+    return;
+}
+
+void thread_cond_signal(struct conditional_variable *conv)
+{
+    int thr_id;
+
+    thread_mutex_lock(&conv->mux); /* protect the queue */
+    thr_id = front(&(conv->q));
+    pop(&(conv->q));
+    thread_mutex_unlock(&conv->mux); /* we're done with the list */
+
+    if (thr_id > 0)
+        thread_wakeup(thr_id);
+
+    return;
+}
\ No newline at end of file
diff --git a/user/user_mutexlock.h b/user/user_mutexlock.h
new file mode 100644
index 0000000..f0083e3
--- /dev/null
+++ b/user/user_mutexlock.h
@@ -0,0 +1,69 @@
+// Mutual exclusion lock.
+#include "kernel/types.h"
+#include "kernel/param.h"
+#include "user/user.h"
+
+
+//same as spinlock, only go to sleep instead of looping.................
+
+struct thread_mutex {
+  uint8 locked;       // Is the lock held?
+  int pid;
+
+};
+// Mutual exclusion mutex locks.
+
+
+void
+thread_mutex_init(struct thread_mutex *mux)
+{
+  mux->locked = 0;
+  mux->pid=getpid();
+}
+
+// Acquire the lock.
+// Loops (mutexs) until the lock is acquired.
+void
+thread_mutex_lock(struct thread_mutex *mux)
+{
+  // if(mux->pid!=getpid())
+  //   printf("PROBLEM IN MUTEX LOCKING\n");
+
+  while(__sync_lock_test_and_set(&mux->locked, 1) != 0)
+  {
+    sleep(1);
+
+  }
+    
+  __sync_synchronize();
+
+}
+
+// Release the lock.
+void
+thread_mutex_unlock(struct thread_mutex *mux)
+{
+  // if(mux->pid!=getpid())
+  //   printf("PROBLEM IN MUTEX UNLOCKING\n");
+
+
+  // Tell the C compiler and the CPU to not move loads or stores
+  // past this point, to ensure that all the stores in the critical
+  // section are visible to other CPUs before the lock is released,
+  // and that loads in the critical section occur strictly before
+  // the lock is released.
+  // On RISC-V, this emits a fence instruction.
+  __sync_synchronize();
+
+  // Release the lock, equivalent to mux->locked = 0.
+  // This code doesn't use a C assignment, since the C standard
+  // implies that an assignment might be implemented with
+  // multiple store instructions.
+  // On RISC-V, sync_lock_release turns into an atomic swap:
+  //   s1 = &mux->locked
+  //   amoswap.w zero, zero, (s1)
+  __sync_lock_release(&mux->locked);
+
+}
+
+
diff --git a/user/user_semaphore.h b/user/user_semaphore.h
new file mode 100644
index 0000000..770a088
--- /dev/null
+++ b/user/user_semaphore.h
@@ -0,0 +1,41 @@
+#include "kernel/types.h"
+#include "kernel/param.h"
+#include "user/user.h"
+#include "user/user_conditional.h"
+
+//used the book....................................
+
+
+struct sem_t {
+    int count; 
+    struct thread_mutex mux;
+    struct conditional_variable conv;
+};
+
+int sem_init(struct sem_t *sem, int value) {
+    sem->count = value;
+    thread_mutex_init(&sem->mux);
+    thread_cond_init(&sem->conv);
+    return 0;
+}
+
+
+void sem_wait(struct sem_t *sem) {
+    thread_mutex_lock(&sem->mux);
+    while (sem->count <= 0) {
+        thread_cond_wait(&sem->conv, &sem->mux); /*unlock mutex, wait, relock mutex */
+    }
+    sem->count--;
+    thread_mutex_unlock(&sem->mux);
+}
+
+void sem_post(struct sem_t *sem) {
+    thread_mutex_lock(&sem->mux);
+    sem->count++;
+    if (sem->count == 1) /* Wake up one waiting thread! */
+        thread_cond_signal(&sem->conv);
+    // thread_cond_signal(&s->conv); /* See note */
+    /* A woken thread must acquire the lock, so it will also have to wait until we call unlock */
+
+    thread_mutex_unlock(&sem->mux);
+}
diff --git a/user/user_spinLock.h b/user/user_spinLock.h
new file mode 100644
index 0000000..5551375
--- /dev/null
+++ b/user/user_spinLock.h
@@ -0,0 +1,74 @@
+
+#include "kernel/types.h"
+#include "kernel/param.h"
+#include "user/user.h"
+//copied spinlock.h
+
+struct thread_spinlock {
+  uint8 locked;       // Is the lock held?
+  int pid;
+};
+// Mutual exclusion spin locks.
+
+
+
+void
+thread_spin_init(struct thread_spinlock *sLock)
+{
+  sLock->locked = 0;
+  sLock->pid=getpid();
+}
+
+// Acquire the lock.
+// Loops (spins) until the lock is acquired.
+void
+thread_spin_lock(struct thread_spinlock *sLock)
+{
+
+  // if(sLock->pid!=getpid())
+  //   printf("PROBLEM IN SPIN LOCKING\n");
+
+
+  // On RISC-V, sync_lock_test_and_set turns into an atomic swap:
+  //   a5 = 1
+  //   s1 = &sLock->locked
+  //   amoswap.w.aq a5, a5, (s1)
+  while(__sync_lock_test_and_set(&sLock->locked, 1) != 0)
+    ;
+
+  // Tell the C compiler and the processor to not move loads or stores
+  // past this point, to ensure that the critical section's memory
+  // references happen strictly after the lock is acquired.
+  // On RISC-V, this emits a fence instruction.
+  __sync_synchronize();
+
+
+}
+
+// Release the lock.
+void
+thread_spin_unlock(struct thread_spinlock *sLock)
+{
+
+  // if(sLock->pid!=getpid())
+  //   printf("PROBLEM IN SPIN UNLOCKING\n");
+
+  // Tell the C compiler and the CPU to not move loads or stores
+  // past this point, to ensure that all the stores in the critical
+  // section are visible to other CPUs before the lock is released,
+  // and that loads in the critical section occur strictly before
+  // the lock is released.
+  // On RISC-V, this emits a fence instruction.
+  __sync_synchronize();
+
+  // Release the lock, equivalent to sLock->locked = 0.
+  // This code doesn't use a C assignment, since the C standard
+  // implies that an assignment might be implemented with
+  // multiple store instructions.
+  // On RISC-V, sync_lock_release turns into an atomic swap:
+  //   s1 = &sLock->locked
+  //   amoswap.w zero, zero, (s1)
+  __sync_lock_release(&sLock->locked);
+
+}
+
diff --git a/user/usys.pl b/user/usys.pl
index 01e426e..363aa4e 100755
--- a/user/usys.pl
+++ b/user/usys.pl
@@ -36,3 +36,8 @@ entry("getpid");
 entry("sbrk");
 entry("sleep");
 entry("uptime");
+entry("thread_create"); #OFFLINE-5..................
+entry("thread_join");
+entry("thread_exit"); 
+entry("atomic_sleep");
+entry("thread_wakeup");
\ No newline at end of file
